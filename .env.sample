# Ollama Model Settings
MODEL=llama2:latest
EMBEDDING_MODEL=all-minilm:l6-v2

# Note: To use host machine's Ollama, use docker-compose.host.yml instead

# GPU Acceleration Settings (for containerized Ollama)
OLLAMA_GPU_DEVICES=all
OLLAMA_GPU_COUNT=1
OLLAMA_GPU_MODE=shared
OLLAMA_GPU_LAYERS=32

# Web Search Integration
SERPER_API_KEY=your_serper_dev_api_key_here